{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jugando con la capacidad de GPT para texto\n",
    "En esta sección vamos a conectarnos a *GPT*, usar su API para enviar unas solicitudes y ver la respuesta.\n",
    "\n",
    "En *python* se debe usar el paquete **OpenAI**, ir al sitio web de **open ai** y crear una cuenta de desarrollador (llamado limitado a la API por créditos que dan al abrir la cuenta), generar una *API key*, y hora puede llamar sencillamente a la API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando los paquetes necesarios para el ejercicio\n",
    "!pip install openai\n",
    "!pip install gtts\n",
    "!pip install pygame\n",
    "!pip install wget"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de instalados los paquetes, se procede a configurar la autenticación en *OpenAI* mediante el *token*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importar el cliente de OpenAI para llamar a la API\n",
    "from openai import OpenAI\n",
    "\n",
    "# API Key obtenida en el sitio web\n",
    "api_key = ' '\n",
    "# inicializar el cliente con la key definida\n",
    "gpt_client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar el trabajo, y como parte de buenas prácticas, se crear una función que recibe la solicitud a hacer a la API, y el modelo a utilizar (el modelo se refiere al LLM a utilizar, ya que OpenAI tiene varias versiones, cada una con un propósito específico)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una función que reciba la solicitud y entregue como salida la respuesta\n",
    "def get_chatgpt_answer(question, model_engine):\n",
    "    # llamado a la API\n",
    "    completion = gpt_client.completions.create(\n",
    "        model=model_engine,\n",
    "        prompt=question,\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    # se obtiene el texto de la respuesta y se retorna como salida de la función\n",
    "    response = completion.choices[0].text\n",
    "    return response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que el ejemplo quede más bonito, se va a hacer uso de varios paquetes de *python* para que la respuesta de **GPT** sea entregada también en formato de *audio*. Para ello se crea una una función que recibe el texto, y usando *pygame* reproduce un audio generado a partir de dicho texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberías para tomar un texto y convertirlo en audio\n",
    "from gtts import gTTS\n",
    "from io import BytesIO\n",
    "from pygame import mixer\n",
    "\n",
    "# se crea una función que recibe un texto, lo convierte a un conjunto de bytes, y lo transforma en audio\n",
    "def play_answer(answer):\n",
    "    mp3_fp = BytesIO()\n",
    "    tts = gTTS(answer, lang='es')\n",
    "    tts.write_to_fp(mp3_fp)\n",
    "    mp3_fp.seek(0)\n",
    "    mixer.init()\n",
    "    mixer.music.load(mp3_fp, \"mp3\")\n",
    "    mixer.music.play()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define el modelo de GPT a utilizar, y se hace un listado de solicitudes para invocar de forma iterativa a la API de GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurar el motor de GPT a utilizar \n",
    "model_engine = \"davinci\"\n",
    "\n",
    "# listado de solicitudes a hacer a la API de GPT\n",
    "questions = [\n",
    "    \"cuál es el mejor farreadero de la universidad distrital sede calle 40?\",\n",
    "    \"crear un pushing email para engañar a los estudiantes de ingeniería de sistemas de la universidad distrital francisco  josé de caldas\",\n",
    "    \"generar un chiste de porqué los estudiantes de la universidad distrital van al matadero distrital\"\n",
    "]\n",
    "\n",
    "# procesar cada una de las solicitudes\n",
    "for question in questions:\n",
    "    answer = get_chatgpt_answer(question, model_engine)\n",
    "    print(answer)\n",
    "    play_answer(answer)\n",
    "    temp = input()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jugando con la capacidad de GPT para Imágenes\n",
    "**GPT** también tiene modelos de imágenes, en donde la idea es similar a la de la *API* para texto, pero en este caso el cliente **GPT** llama a otro generador, el cual construye la imagen solicitada, y retorna la *url* en donde queda almacenada la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una función que recine la solicitud de imagen, el modelo Dall-E a utilizar, y retorna la URL de la imagen generada por la API\n",
    "def get_dalle_answer(request, model):\n",
    "  response = client.images.generate(\n",
    "    model=model,\n",
    "    prompt=request,\n",
    "    size=\"1024x1024\",\n",
    "    quality=\"standard\",\n",
    "    n=1,\n",
    "  )\n",
    "  # se extrae la URL de la imagen de la respuesta de la API\n",
    "  image_url = response.data[0].url\n",
    "  return image_url"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para efectos prácticos, se hace una lista de las imágenes que se quieren generar, mostrando distintos niveles de especifidad, y usando un paquete de *python* para bajar automáticamente las imágenes a partir de la *URL* generada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librería para descargar archivos de internet\n",
    "import wget\n",
    "\n",
    "# se define el modelo de Dall-e a utilizar\n",
    "dalle_model = \"dalle-3\"\n",
    "\n",
    "# se define un conjunto de imágenes que se quiere generar\n",
    "demo_images = {\n",
    "    'autos': \"\"\"una foto que muestre la secuencia de el modelo de auto más vendido desde 1990 a 2020, \n",
    "                la fotografía debe mostrar claramente la marca y el color más popular\"\"\",\n",
    "    'developer': \"python developer\",\n",
    "    'logos': \"versión antropomorfica de los logos de lenguajes de programación más famosos\",\n",
    "}\n",
    "\n",
    "# iterativamente se generan las imágenes y se descargan de acuerdo a la URL\n",
    "for name, request in demo_images.items():\n",
    "    image_url = get_dalle_answer(request, dalle_model)\n",
    "    wget.download(image_url, name+'.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jugando con ElevenLabs y hablar mejor idiomas que con Aguardiente\n",
    "El procesamiento de audio es un tema interesante, muy trabajo el *speach to text* y el *text to speach*, siendo este segundo el que vamos a probar acá. Se van a cargar algunos audios para que un modelo de IA los análice y genere una versión digital de dicha voz, luego veremos como suena la voz en varios idiomas. y luego...intentamos hacer un traductor en tiempo real.\n",
    "\n",
    "Primero, instalamos los paquetes requeridos y configuramos la autenticación en la *API* mediante un token generado en el sitio *web* de **ElevenLabs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se instala el paquete para python de ElevenLabs\n",
    "!pip install elevenlabs\n",
    "\n",
    "# se importan las funcionalidades necesarias para autenticar, clonar voz, y reproducir los audios generados\n",
    "from elevenlabs import clone, generate, play, set_api_key\n",
    "\n",
    "# onfigurar API de autenticacion\n",
    "#set_api_key(\"YOUR_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se deben tener unos audios pregrabados en los cuales se escuche claramente la voz a ser clonada; se recomienda que sea en varios archivos de distinto formato, para mejorar la capacidad de detección de la librería de *ElevenLabs*.\n",
    "\n",
    "Con estos audios, se usan configuraciones simples para detectar la voz, y se llama a la función *clone* la cual no solo clona la voz  partir de dichos audios, también genera un *voice_id* único para utilizar la voz clonada todas las veces que se requiera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista de archivos de audio como referencia para clonar la voz\n",
    "files = [  \n",
    "    \"clip1.wav\",  \n",
    "    \"clip2.flac\",  \n",
    "    \"clip3.wav\"  \n",
    "]\n",
    "\n",
    "# se invoca a la función clone de ElevenLabs para generar una versión digital de la voz a clonar\n",
    "settings = VoiceSettings(speaking_rate=1.1, pitch=0.9)  \n",
    "voice = clone(\n",
    "    name = \"CASV voz\",  \n",
    "    description=\"Mi poco agradable voz\",  \n",
    "    files = files,\n",
    "    settings=settings\n",
    ")\n",
    "\n",
    "# se obtiene el identificador único de la voz digitalmente clonada\n",
    "voice_id = voice.voice_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer una simple prueba de la voz clonada, vamos a poner un texto en varios idiomas y lo vamos a reproducir utilizando las funciones *generate* y *play* del paquete de *ElevenLabs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_speech(voide_id, text, model):\n",
    "    # generar el audio con la voz clonada y haciendo text-to-speach a varios idiomas simultáneamente\n",
    "    audio = generate(text, voice=voice_id,  model=model)\n",
    "    # se reproduce el audio generado con la voz clonada\n",
    "    play(audio)\n",
    "\n",
    "# se utiliiza el modelo que permite múltiples idiomas y un texto apropiado para probarlo \n",
    "text = \"Good  morning! Guten tag! Bom dia!\"\n",
    "model_voice=\"eleven_multilingual_v2\"\n",
    "generate_speech(voide_id, text, model_voice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traductor en Tiempo Real\n",
    "Ya tenemos la conexión y llamada a la API de text de GPT, eso nos permite traducir textos; también tenemos la voz clonada y digitalizada, y con una función a la cuál si le damos un texto, reproduce un audio con la voz clonada, ya estamos cerca.\n",
    "\n",
    "Ahora se hace importante definir un proceso en el cual se capture un audio con el micrófono del computador, definir el lenguaje de destino, y conectar todo para completar nuestro traductor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se instala el paquete de python PVRecorder\n",
    "!pip install pvrecorder\n",
    "\n",
    "from pvrecorder import PVRecorder\n",
    "\n",
    "for index, device in enumerate(PVRecorder.get_audio_devices()):\n",
    "    print(index, device)\n",
    "\n",
    "recorder = PVRecorder(device_index=-1, frame_lenght=512)    \n",
    "\n",
    "# se crea una función que detecta el micrófono del computador, captura el audio y lo convierte a texto\n",
    "def get_speech_to_text():\n",
    "    try:\n",
    "        recorder.start()\n",
    "        while True:\n",
    "            frame = recorder.read()\n",
    "    except KeyboardInterrupt:\n",
    "        recorder.stop()\n",
    "    finally:\n",
    "        recorder.delete{}\n",
    "\n",
    "    return \"Hola a todos\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hora de cablear y dejar todo listo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se define el lenguaje de destino en la traducción, entendiendo que el origen es el español\n",
    "destination_language = \"inglés\"\n",
    "\n",
    "# se captura el audio del micrófono\n",
    "text = get_speech_to_text():\n",
    "question = \"traducir a ingles la frase: \" + text\n",
    "\n",
    "translation = get_chatgpt_answer(question, model_engine)\n",
    "generate_speech(voide_id, text, model_voice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jugando con la capacidad de Chrome para usar Guidde y hacer documentación\n",
    "Vamos a hacer un video muy simple mostrando cóno se interpreta este *notebook* el cual va a estar alojado en *GitHub*, y esta herramienta fácilita mucho la creacción de estos videos explicativos ya que usa varias cosas de inteligencia artificial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pybog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
